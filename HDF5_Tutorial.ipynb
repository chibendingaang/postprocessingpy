{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to HDF5 with `h5py`\n",
    "\n",
    "In this notebook, we will explore the basics of working with HDF5 files using the `h5py` package in Python. We'll cover the concepts of HDF5 files, datasets, and how to manage and access data stored in HDF5 format.\n",
    "\n",
    "## 1. HDF5 Files and Datasets\n",
    "\n",
    "### HDF5 File\n",
    "- An HDF5 file is a container for storing datasets and groups in a hierarchical manner.\n",
    "- It can contain multiple datasets and groups, organized in a tree structure.\n",
    "\n",
    "### Dataset\n",
    "- A dataset in HDF5 is a multidimensional array of data.\n",
    "- It can hold data of any type (e.g., integers, floats, strings).\n",
    "- Each dataset is accessed by a unique name within the HDF5 file.\n",
    "\n",
    "### Groups\n",
    "- Groups are containers within HDF5 files that can hold datasets and other groups.\n",
    "- They help organize datasets hierarchically.\n",
    "\n",
    "## 2. Basic Operations with `h5py`\n",
    "\n",
    "### Example 1: Reading and Writing a NumPy Array\n",
    "```python\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Create a simple NumPy array\n",
    "data = np.arange(100).reshape(10, 10)\n",
    "\n",
    "# Writing to an HDF5 file\n",
    "with h5py.File('example1.h5', 'w') as h5f:\n",
    "    h5f.create_dataset('my_dataset', data=data)\n",
    "    \n",
    "# Reading from the HDF5 file\n",
    "with h5py.File('example1.h5', 'r') as h5f:\n",
    "    loaded_data = h5f['my_dataset'][:]\n",
    "    print(loaded_data)\n",
    "```\n",
    "\n",
    "### Example 2: Reading and Writing a CSV File\n",
    "```python\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Load data from a CSV file into a NumPy array\n",
    "csv_data = np.loadtxt('example2.csv', delimiter=',')\n",
    "\n",
    "# Writing to an HDF5 file\n",
    "with h5py.File('example2.h5', 'w') as h5f:\n",
    "    h5f.create_dataset('csv_dataset', data=csv_data)\n",
    "    \n",
    "# Reading from the HDF5 file\n",
    "with h5py.File('example2.h5', 'r') as h5f:\n",
    "    loaded_csv_data = h5f['csv_dataset'][:]\n",
    "    print(loaded_csv_data)\n",
    "```\n",
    "\n",
    "## 3. Using Dataset Options\n",
    "\n",
    "### Compression\n",
    "```python\n",
    "with h5py.File('compressed_example.h5', 'w') as h5f:\n",
    "    h5f.create_dataset('compressed_dataset', data=data, compression='gzip', compression_opts=4)\n",
    "```\n",
    "- **`compression='gzip'`**: Uses gzip algorithm for compression.\n",
    "- **`compression_opts=4`**: Sets the compression level (0-9).\n",
    "\n",
    "### Chunking\n",
    "```python\n",
    "with h5py.File('chunked_example.h5', 'w') as h5f:\n",
    "    h5f.create_dataset('chunked_dataset', data=data, chunks=(5, 5))\n",
    "```\n",
    "- **`chunks=(5, 5)`**: Defines the size of chunks (blocks of data).\n",
    "\n",
    "### Data Types\n",
    "```python\n",
    "with h5py.File('dtype_example.h5', 'w') as h5f:\n",
    "    h5f.create_dataset('int_dataset', data=data, dtype='int32')\n",
    "```\n",
    "- **`dtype='int32'`**: Specifies the data type for the dataset.\n",
    "\n",
    "## 4. Working with Groups\n",
    "```python\n",
    "with h5py.File('group_example.h5', 'w') as h5f:\n",
    "    group = h5f.create_group('my_group')\n",
    "    group.create_dataset('grouped_dataset', data=data)\n",
    "```\n",
    "- **`create_group('my_group')`**: Creates a group named `my_group`.\n",
    "- **`group.create_dataset()`**: Creates a dataset within the specified group.\n",
    "\n",
    "## Summary\n",
    "In this tutorial, we covered:\n",
    "- The basic concepts of HDF5 files and datasets.\n",
    "- How to read and write data using `h5py`.\n",
    "- Various options for creating datasets, such as compression and chunking.\n",
    "- How to use groups to organize datasets hierarchically.\n",
    "\n",
    "With these concepts, you should be able to efficiently store and manage large datasets using HDF5. If you have more questions or need further clarification, feel free to ask!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}


